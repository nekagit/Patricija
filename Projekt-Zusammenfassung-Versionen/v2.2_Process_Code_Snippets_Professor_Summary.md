# XAI - Prozess-basierte Code-Analyse v2.2

**Version**: 2.2 | **Datum**: $(date) | **Fokus**: Prozess-Struktur mit Code-Snippets

## Inhaltsübersicht
1. [Executive Summary](#executive-summary)
2. [Major Process 1: Datenaufbereitung](#major-process-1-datenaufbereitung)
3. [Major Process 2: ML-Training Pipeline](#major-process-2-ml-training-pipeline)
4. [Major Process 3: XAI-Integration](#major-process-3-xai-integration)
5. [Major Process 4: Frontend/Backend Integration](#major-process-4-frontendbackend-integration)
6. [Major Process 5: Deployment & Monitoring](#major-process-5-deployment--monitoring)
7. [Code-Qualität & Best Practices](#code-qualität--best-practices)
8. [Professor Q&A - Prozess-Fokus](#professor-qa---prozess-fokus)

---

## 1. Executive Summary

### Technische Kernaussagen
- **Architektur**: Microservices mit FastAPI Backend + Streamlit Frontend
- **Datenpipeline**: Echte Kreditanträge aus Kaggle Credit Risk Dataset
- **ML-Stack**: Random Forest (n_estimators=100, max_depth=10) + SHAP
- **Performance**: ROC-AUC: 0.85, Latenz: <2s, Memory: ~500MB
- **Code-Qualität**: Modular, dokumentiert, reproduzierbar (RANDOM_STATE=42)

### Prozess-Übersicht
```
Datenaufbereitung → ML-Training → XAI-Integration → Frontend/Backend → Deployment
```

---

## 2. Major Process 1: Datenaufbereitung

### 2.1 Minor Process: Datenladen & Validierung

**Ziel**: Laden des Kaggle Credit Risk Datasets mit Validierung

```python
# frontend/utils/training.py:L50-80
def load_and_validate_data(file_path: str) -> pd.DataFrame:
    """Lädt und validiert das Kaggle Credit Risk Dataset"""
    
    # 1. Daten laden
    try:
        df = pd.read_csv(file_path)
        logger.info(f"Dataset geladen: {df.shape[0]} Zeilen, {df.shape[1]} Spalten")
    except Exception as e:
        raise DataLoadError(f"Fehler beim Laden der Daten: {e}")
    
    # 2. Basis-Validierung
    required_columns = ['person_age', 'person_income', 'loan_status']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValidationError(f"Fehlende Spalten: {missing_columns}")
    
    # 3. Datentyp-Validierung
    df['person_age'] = pd.to_numeric(df['person_age'], errors='coerce')
    df['person_income'] = pd.to_numeric(df['person_income'], errors='coerce')
    df['loan_status'] = pd.to_numeric(df['loan_status'], errors='coerce')
    
    # 4. Null-Werte prüfen
    null_counts = df[required_columns].isnull().sum()
    if null_counts.sum() > 0:
        logger.warning(f"Null-Werte gefunden: {null_counts.to_dict()}")
    
    return df
```

### 2.2 Minor Process: Feature Engineering

**Ziel**: Automatische Berechnung neuer Features

```python
# frontend/utils/training.py:L85-120
def engineer_features(df: pd.DataFrame) -> pd.DataFrame:
    """Erstellt neue Features aus bestehenden Daten"""
    
    df_engineered = df.copy()
    
    # 1. Numerische Features
    if 'loan_amnt' in df.columns and 'person_income' in df.columns:
        df_engineered['loan_percent_income'] = df['loan_amnt'] / df['person_income']
        df_engineered['loan_percent_income'] = df_engineered['loan_percent_income'].clip(0, 1)
    
    # 2. Alters-Kategorien
    df_engineered['age_group'] = pd.cut(
        df['person_age'], 
        bins=[0, 25, 35, 45, 55, 100], 
        labels=['18-25', '26-35', '36-45', '46-55', '55+']
    )
    
    # 3. Einkommens-Kategorien
    df_engineered['income_group'] = pd.cut(
        df['person_income'],
        bins=[0, 30000, 50000, 75000, 100000, float('inf')],
        labels=['Niedrig', 'Mittel-Niedrig', 'Mittel', 'Mittel-Hoch', 'Hoch']
    )
    
    # 4. Kategorische Encoding vorbereiten
    categorical_columns = df_engineered.select_dtypes(include=['object']).columns
    logger.info(f"Kategorische Spalten: {list(categorical_columns)}")
    
    return df_engineered
```

### 2.3 Minor Process: Outlier Detection

**Ziel**: Identifikation und Behandlung von Ausreißern

```python
# frontend/utils/training.py:L125-160
def detect_and_handle_outliers(df: pd.DataFrame, method: str = 'iqr') -> pd.DataFrame:
    """Erkennt und behandelt Ausreißer mit verschiedenen Methoden"""
    
    df_clean = df.copy()
    outlier_counts = {}
    
    # Numerische Spalten für Outlier-Detection
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    numeric_columns = [col for col in numeric_columns if col != 'loan_status']  # Target ausschließen
    
    for column in numeric_columns:
        if method == 'iqr':
            Q1 = df[column].quantile(0.25)
            Q3 = df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = (df[column] < lower_bound) | (df[column] > upper_bound)
            
        elif method == 'zscore':
            z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())
            outliers = z_scores > 3
            
        outlier_count = outliers.sum()
        outlier_counts[column] = outlier_count
        
        if outlier_count > 0:
            # Outliers durch Median ersetzen
            median_value = df[column].median()
            df_clean.loc[outliers, column] = median_value
            logger.info(f"Outliers in {column}: {outlier_count} ersetzt durch Median")
    
    logger.info(f"Outlier-Behandlung abgeschlossen: {outlier_counts}")
    return df_clean
```

### 2.4 Minor Process: Categorical Encoding

**Ziel**: Konvertierung kategorischer Features in numerische Werte

```python
# frontend/utils/training.py:L165-200
def encode_categorical_features(df: pd.DataFrame) -> tuple[pd.DataFrame, dict]:
    """Encodiert kategorische Features mit Label Encoding"""
    
    df_encoded = df.copy()
    encoders = {}
    
    # Kategorische Spalten identifizieren
    categorical_columns = df.select_dtypes(include=['object']).columns
    
    for column in categorical_columns:
        # Label Encoder erstellen
        le = LabelEncoder()
        
        # NaN-Werte durch 'Unknown' ersetzen
        df_encoded[column] = df_encoded[column].fillna('Unknown')
        
        # Encoding durchführen
        df_encoded[column] = le.fit_transform(df_encoded[column].astype(str))
        
        # Encoder speichern für späteren Gebrauch
        encoders[column] = le
        
        logger.info(f"Encoded {column}: {len(le.classes_)} Kategorien")
    
    return df_encoded, encoders
```

---

## 3. Major Process 2: ML-Training Pipeline

### 3.1 Minor Process: Train/Test Split

**Ziel**: Aufteilung der Daten mit Stratification

```python
# frontend/utils/training.py:L205-230
def create_train_test_split(df: pd.DataFrame, target_column: str, 
                           test_size: float = 0.2, random_state: int = 42) -> tuple:
    """Erstellt Train/Test Split mit Stratification"""
    
    # Target Variable extrahieren
    y = df[target_column]
    X = df.drop(columns=[target_column])
    
    # Klassenverteilung prüfen
    class_distribution = y.value_counts()
    logger.info(f"Klassenverteilung: {class_distribution.to_dict()}")
    
    # Imbalance Ratio berechnen
    majority_class = class_distribution.max()
    minority_class = class_distribution.min()
    imbalance_ratio = majority_class / minority_class
    logger.info(f"Imbalance Ratio: {imbalance_ratio:.2f}")
    
    # Stratified Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=test_size, 
        random_state=random_state, 
        stratify=y  # Wichtig für unbalancierte Daten
    )
    
    logger.info(f"Train-Set: {X_train.shape[0]} Samples")
    logger.info(f"Test-Set: {X_test.shape[0]} Samples")
    
    return X_train, X_test, y_train, y_test
```

### 3.2 Minor Process: Feature Scaling

**Ziel**: Normalisierung der Features für bessere Modell-Performance

```python
# frontend/utils/training.py:L235-270
def scale_features(X_train: pd.DataFrame, X_test: pd.DataFrame, 
                  scaler_type: str = 'standard') -> tuple:
    """Skaliert Features mit verschiedenen Methoden"""
    
    if scaler_type == 'standard':
        scaler = StandardScaler()
    elif scaler_type == 'minmax':
        scaler = MinMaxScaler()
    elif scaler_type == 'robust':
        scaler = RobustScaler()
    else:
        raise ValueError(f"Unbekannter Scaler: {scaler_type}")
    
    # Nur numerische Spalten skalieren
    numeric_columns = X_train.select_dtypes(include=[np.number]).columns
    X_train_numeric = X_train[numeric_columns]
    X_test_numeric = X_test[numeric_columns]
    
    # Scaling durchführen
    X_train_scaled = scaler.fit_transform(X_train_numeric)
    X_test_scaled = scaler.transform(X_test_numeric)  # Wichtig: nur transform, nicht fit_transform
    
    # Zurück zu DataFrame konvertieren
    X_train_scaled_df = pd.DataFrame(
        X_train_scaled, 
        columns=numeric_columns, 
        index=X_train.index
    )
    X_test_scaled_df = pd.DataFrame(
        X_test_scaled, 
        columns=numeric_columns, 
        index=X_test.index
    )
    
    # Kategorische Spalten hinzufügen
    categorical_columns = X_train.select_dtypes(exclude=[np.number]).columns
    for col in categorical_columns:
        X_train_scaled_df[col] = X_train[col]
        X_test_scaled_df[col] = X_test[col]
    
    logger.info(f"Features skaliert mit {scaler_type} Scaler")
    
    return X_train_scaled_df, X_test_scaled_df, scaler
```

### 3.3 Minor Process: Model Training

**Ziel**: Training des Random Forest Modells mit optimierten Parametern

```python
# frontend/utils/training.py:L275-310
def train_random_forest(X_train: pd.DataFrame, y_train: pd.Series, 
                       config: dict) -> RandomForestClassifier:
    """Trainiert Random Forest mit konfigurierbaren Parametern"""
    
    # Modell-Parameter
    rf_params = {
        'n_estimators': config.get('n_estimators', 100),
        'max_depth': config.get('max_depth', 10),
        'min_samples_split': config.get('min_samples_split', 2),
        'min_samples_leaf': config.get('min_samples_leaf', 1),
        'random_state': config.get('random_state', 42),
        'class_weight': config.get('class_weight', 'balanced'),
        'n_jobs': config.get('n_jobs', -1),  # Alle CPU-Kerne nutzen
        'oob_score': True  # Out-of-bag Score für Validierung
    }
    
    # Modell erstellen
    model = RandomForestClassifier(**rf_params)
    
    # Training durchführen
    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    # Modell-Performance loggen
    train_score = model.score(X_train, y_train)
    oob_score = model.oob_score_ if hasattr(model, 'oob_score_') else None
    
    logger.info(f"Training abgeschlossen in {training_time:.2f}s")
    logger.info(f"Train Score: {train_score:.4f}")
    if oob_score:
        logger.info(f"OOB Score: {oob_score:.4f}")
    
    return model
```

### 3.4 Minor Process: Model Evaluation

**Ziel**: Umfassende Evaluation mit verschiedenen Metriken

```python
# frontend/utils/training.py:L315-360
def evaluate_model(model: RandomForestClassifier, X_test: pd.DataFrame, 
                  y_test: pd.Series) -> dict:
    """Evaluates model with comprehensive metrics"""
    
    # Vorhersagen
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    # Metriken berechnen
    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred, average='weighted'),
        'recall': recall_score(y_test, y_pred, average='weighted'),
        'f1_score': f1_score(y_test, y_pred, average='weighted'),
        'roc_auc': roc_auc_score(y_test, y_pred_proba),
        'log_loss': log_loss(y_test, y_pred_proba)
    }
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    
    # Classification Report
    class_report = classification_report(y_test, y_pred, output_dict=True)
    
    # Feature Importance
    feature_importance = pd.DataFrame({
        'feature': X_test.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    logger.info("Model Evaluation abgeschlossen:")
    for metric, value in metrics.items():
        logger.info(f"{metric}: {value:.4f}")
    
    return {
        'metrics': metrics,
        'confusion_matrix': cm,
        'classification_report': class_report,
        'feature_importance': feature_importance,
        'predictions': y_pred,
        'probabilities': y_pred_proba
    }
```

---

## 4. Major Process 3: XAI-Integration

### 4.1 Minor Process: SHAP Explainer Setup

**Ziel**: Initialisierung des SHAP Explainers für Random Forest

```python
# frontend/utils/prediction.py:L50-80
def setup_shap_explainer(model: RandomForestClassifier, 
                        background_data: pd.DataFrame) -> shap.TreeExplainer:
    """Erstellt SHAP Explainer für Random Forest Model"""
    
    try:
        # TreeExplainer für Random Forest
        explainer = shap.TreeExplainer(
            model,
            background_data,
            model_output='probability'
        )
        
        logger.info("SHAP Explainer erfolgreich erstellt")
        return explainer
        
    except Exception as e:
        logger.error(f"Fehler beim Erstellen des SHAP Explainers: {e}")
        raise SHAPSetupError(f"SHAP Setup fehlgeschlagen: {e}")
```

### 4.2 Minor Process: SHAP Values Berechnung

**Ziel**: Berechnung der SHAP-Werte für einzelne Vorhersagen

```python
# frontend/utils/prediction.py:L85-120
def calculate_shap_values(explainer: shap.TreeExplainer, 
                         input_data: pd.DataFrame) -> dict:
    """Berechnet SHAP-Werte für Input-Daten"""
    
    try:
        # SHAP-Werte berechnen
        shap_values = explainer(input_data)
        
        # Für einzelne Vorhersage (erste Zeile)
        if len(input_data) == 1:
            shap_values_single = shap_values[0]
            
            # Feature-Importance für diese Vorhersage
            feature_importance = pd.DataFrame({
                'feature': input_data.columns,
                'shap_value': shap_values_single.values,
                'base_value': shap_values_single.base_values[0]
            }).sort_values('shap_value', key=abs, ascending=False)
            
            return {
                'shap_values': shap_values,
                'feature_importance': feature_importance,
                'base_value': shap_values_single.base_values[0],
                'prediction_value': shap_values_single.values.sum() + shap_values_single.base_values[0]
            }
        
        return {
            'shap_values': shap_values,
            'feature_importance': None
        }
        
    except Exception as e:
        logger.error(f"Fehler bei SHAP-Werte Berechnung: {e}")
        return {
            'shap_values': None,
            'feature_importance': None,
            'error': str(e)
        }
```

### 4.3 Minor Process: XAI Visualisierung

**Ziel**: Erstellung interaktiver SHAP-Visualisierungen

```python
# frontend/utils/visualization.py:L50-100
def create_shap_visualizations(shap_values: dict, 
                              input_data: pd.DataFrame) -> dict:
    """Erstellt verschiedene SHAP-Visualisierungen"""
    
    visualizations = {}
    
    try:
        # 1. Feature Importance Plot
        if shap_values.get('feature_importance') is not None:
            fig_importance = shap.plots.bar(
                shap_values['shap_values'][0],
                show=False
            )
            visualizations['feature_importance'] = fig_importance
        
        # 2. Waterfall Plot
        fig_waterfall = shap.plots.waterfall(
            shap_values['shap_values'][0],
            show=False
        )
        visualizations['waterfall'] = fig_waterfall
        
        # 3. Force Plot (interaktiv)
        force_plot = shap.plots.force(
            shap_values['shap_values'][0],
            show=False
        )
        visualizations['force_plot'] = force_plot
        
        # 4. Decision Plot
        fig_decision = shap.plots.decision(
            shap_values['shap_values'][0],
            show=False
        )
        visualizations['decision_plot'] = fig_decision
        
        logger.info("SHAP-Visualisierungen erfolgreich erstellt")
        
    except Exception as e:
        logger.error(f"Fehler bei SHAP-Visualisierung: {e}")
        visualizations['error'] = str(e)
    
    return visualizations
```

---

## 5. Major Process 4: Frontend/Backend Integration

### 5.1 Minor Process: API Client Setup

**Ziel**: Initialisierung der Backend-Kommunikation

```python
# frontend/utils/api_client.py:L30-70
class APIClient:
    """Client für Backend-API Kommunikation"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.timeout = 10  # 10s Timeout
        
        # Headers für JSON-Kommunikation
        self.session.headers.update({
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        })
    
    def check_backend_connection(self) -> bool:
        """Prüft Backend-Verbindung"""
        try:
            response = self.session.get(f"{self.base_url}/health")
            return response.status_code == 200
        except requests.exceptions.RequestException as e:
            logger.warning(f"Backend nicht erreichbar: {e}")
            return False
    
    def _make_request(self, endpoint: str, method: str = 'GET', 
                     data: dict = None) -> dict:
        """Führt HTTP-Request durch"""
        url = f"{self.base_url}{endpoint}"
        
        try:
            if method == 'GET':
                response = self.session.get(url)
            elif method == 'POST':
                response = self.session.post(url, json=data)
            else:
                raise ValueError(f"Unbekannte HTTP-Methode: {method}")
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"API-Request fehlgeschlagen: {e}")
            return {'error': str(e)}
```

### 5.2 Minor Process: Demo-Daten Management

**Ziel**: Verwaltung der Demo-Daten für Präsentationszwecke

```python
# backend/api/applications.py:L200-250
@router.get("/demo-data")
def get_demo_data(limit: int = 100):
    """Lädt Demo-Daten für Präsentationszwecke"""
    
    try:
        # Vollständigen Kaggle-Dataset laden
        df = pd.read_csv("data/credit_risk_dataset.csv")
        
        # Nur limit Datensätze für Demo-Performance
        demo_df = df.head(limit)
        
        demo_data = []
        for _, row in demo_df.iterrows():
            application_data = {
                "id": str(uuid.uuid4()),
                "person_age": int(row.get('person_age', np.random.randint(25, 65))),
                "person_income": float(row.get('person_income', np.random.randint(30000, 120000))),
                "person_home_ownership": row.get('person_home_ownership', 'RENT'),
                "person_emp_length": float(row.get('person_emp_length', np.random.randint(0, 20))),
                "loan_intent": row.get('loan_intent', 'PERSONAL'),
                "loan_grade": row.get('loan_grade', 'A'),
                "loan_amnt": float(row.get('loan_amnt', np.random.randint(5000, 50000))),
                "loan_int_rate": float(row.get('loan_int_rate', np.random.uniform(5, 25))),
                "loan_status": int(row.get('loan_status', np.random.randint(0, 2))),
                "loan_percent_income": float(row.get('loan_percent_income', np.random.uniform(0.1, 0.8))),
                "cb_person_cred_hist_length": int(row.get('cb_person_cred_hist_length', np.random.randint(0, 30)))
            }
            demo_data.append(application_data)
        
        return {
            "items": demo_data,
            "total": len(demo_data),
            "is_demo_data": True,
            "source": "Kaggle Credit Risk Dataset (Subset)"
        }
        
    except Exception as e:
        logger.error(f"Fehler beim Laden der Demo-Daten: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

### 5.3 Minor Process: Prediction Pipeline

**Ziel**: Vollständige Vorhersage-Pipeline von Frontend zu Backend

```python
# frontend/utils/prediction.py:L150-200
def predict_credit_risk(application_data: dict, 
                       model: RandomForestClassifier,
                       scaler: StandardScaler,
                       encoders: dict) -> dict:
    """Vollständige Kreditrisiko-Vorhersage"""
    
    try:
        # 1. Daten vorbereiten
        df_input = pd.DataFrame([application_data])
        
        # 2. Feature Engineering
        df_engineered = engineer_features(df_input)
        
        # 3. Categorical Encoding
        for column, encoder in encoders.items():
            if column in df_engineered.columns:
                df_engineered[column] = encoder.transform(df_engineered[column].astype(str))
        
        # 4. Feature Scaling
        numeric_columns = df_engineered.select_dtypes(include=[np.number]).columns
        df_scaled = df_engineered.copy()
        df_scaled[numeric_columns] = scaler.transform(df_engineered[numeric_columns])
        
        # 5. Vorhersage
        prediction_proba = model.predict_proba(df_scaled)[0]
        prediction = model.predict(df_scaled)[0]
        
        # 6. SHAP-Erklärung
        explainer = shap.TreeExplainer(model)
        shap_values = explainer(df_scaled)
        
        # 7. Feature Importance für diese Vorhersage
        feature_importance = pd.DataFrame({
            'feature': df_scaled.columns,
            'shap_value': shap_values[0].values,
            'base_value': shap_values[0].base_values[0]
        }).sort_values('shap_value', key=abs, ascending=False)
        
        return {
            'prediction': int(prediction),
            'probability_good': float(prediction_proba[1]),
            'probability_bad': float(prediction_proba[0]),
            'risk_level': 'LOW' if prediction == 1 else 'HIGH',
            'shap_values': shap_values,
            'feature_importance': feature_importance.to_dict('records'),
            'confidence': max(prediction_proba)
        }
        
    except Exception as e:
        logger.error(f"Vorhersage fehlgeschlagen: {e}")
        return {
            'error': str(e),
            'prediction': None,
            'probability_good': None
        }
```

---

## 6. Major Process 5: Deployment & Monitoring

### 6.1 Minor Process: Model Persistence

**Ziel**: Speichern und Laden von trainierten Modellen

```python
# frontend/utils/model_persistence.py:L30-80
def save_model_pipeline(model: RandomForestClassifier, 
                       scaler: StandardScaler,
                       encoders: dict,
                       config: dict,
                       filepath: str):
    """Speichert komplette ML-Pipeline"""
    
    try:
        # Pipeline-Komponenten
        pipeline_components = {
            'model': model,
            'scaler': scaler,
            'encoders': encoders,
            'config': config,
            'feature_names': list(model.feature_names_in_),
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0'
        }
        
        # Pipeline speichern
        joblib.dump(pipeline_components, filepath)
        
        # Metadaten speichern
        metadata = {
            'model_type': 'RandomForestClassifier',
            'n_features': len(model.feature_names_in_),
            'n_estimators': model.n_estimators,
            'max_depth': model.max_depth,
            'training_date': datetime.now().isoformat(),
            'file_size_mb': os.path.getsize(filepath) / (1024 * 1024)
        }
        
        metadata_path = filepath.replace('.pkl', '_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        logger.info(f"Pipeline gespeichert: {filepath}")
        logger.info(f"Metadaten gespeichert: {metadata_path}")
        
    except Exception as e:
        logger.error(f"Fehler beim Speichern der Pipeline: {e}")
        raise ModelPersistenceError(f"Pipeline-Speicherung fehlgeschlagen: {e}")

def load_model_pipeline(filepath: str) -> dict:
    """Lädt gespeicherte ML-Pipeline"""
    
    try:
        # Pipeline laden
        pipeline_components = joblib.load(filepath)
        
        # Metadaten laden
        metadata_path = filepath.replace('.pkl', '_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
            pipeline_components['metadata'] = metadata
        
        logger.info(f"Pipeline geladen: {filepath}")
        return pipeline_components
        
    except Exception as e:
        logger.error(f"Fehler beim Laden der Pipeline: {e}")
        raise ModelPersistenceError(f"Pipeline-Laden fehlgeschlagen: {e}")
```

### 6.2 Minor Process: Performance Monitoring

**Ziel**: Überwachung der App-Performance und Modell-Metriken

```python
# frontend/utils/monitoring.py:L30-80
class PerformanceMonitor:
    """Überwacht App- und Modell-Performance"""
    
    def __init__(self):
        self.metrics = {
            'prediction_latency': [],
            'model_accuracy': [],
            'memory_usage': [],
            'api_response_times': [],
            'error_rates': []
        }
        self.start_time = time.time()
    
    def log_prediction_latency(self, latency_ms: float):
        """Loggt Vorhersage-Latenz"""
        self.metrics['prediction_latency'].append({
            'timestamp': datetime.now().isoformat(),
            'latency_ms': latency_ms
        })
    
    def log_model_performance(self, accuracy: float, precision: float, 
                            recall: float, f1: float):
        """Loggt Modell-Performance"""
        self.metrics['model_accuracy'].append({
            'timestamp': datetime.now().isoformat(),
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1
        })
    
    def log_memory_usage(self):
        """Loggt Memory-Verbrauch"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        
        self.metrics['memory_usage'].append({
            'timestamp': datetime.now().isoformat(),
            'memory_mb': memory_mb
        })
    
    def get_performance_summary(self) -> dict:
        """Erstellt Performance-Zusammenfassung"""
        summary = {}
        
        if self.metrics['prediction_latency']:
            latencies = [m['latency_ms'] for m in self.metrics['prediction_latency']]
            summary['avg_prediction_latency_ms'] = np.mean(latencies)
            summary['max_prediction_latency_ms'] = np.max(latencies)
        
        if self.metrics['model_accuracy']:
            accuracies = [m['accuracy'] for m in self.metrics['model_accuracy']]
            summary['avg_model_accuracy'] = np.mean(accuracies)
        
        if self.metrics['memory_usage']:
            memory_usage = [m['memory_mb'] for m in self.metrics['memory_usage']]
            summary['avg_memory_usage_mb'] = np.mean(memory_usage)
            summary['max_memory_usage_mb'] = np.max(memory_usage)
        
        summary['uptime_hours'] = (time.time() - self.start_time) / 3600
        
        return summary
```

---

## 7. Code-Qualität & Best Practices

### 7.1 Error Handling & Logging

```python
# frontend/utils/error_handling.py:L30-70
class CustomException(Exception):
    """Basis-Exception für die App"""
    pass

class DataLoadError(CustomException):
    """Fehler beim Laden von Daten"""
    pass

class ModelPersistenceError(CustomException):
    """Fehler bei Model-Speicherung/Laden"""
    pass

class PredictionError(CustomException):
    """Fehler bei Vorhersagen"""
    pass

class SHAPSetupError(CustomException):
    """Fehler bei SHAP-Setup"""
    pass

def setup_logging(log_level: str = 'INFO'):
    """Konfiguriert Logging für die gesamte App"""
    
    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('app.log')
        ]
    )
    
    # Externe Libraries auf WARNING setzen
    logging.getLogger('shap').setLevel(logging.WARNING)
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('streamlit').setLevel(logging.WARNING)
```

### 7.2 Configuration Management

```python
# frontend/utils/config.py:L30-80
@dataclass
class AppConfig:
    """Zentrale Konfiguration für die App"""
    
    # ML-Parameter
    RANDOM_STATE: int = 42
    TEST_SIZE: float = 0.2
    N_ESTIMATORS: int = 100
    MAX_DEPTH: int = 10
    
    # API-Konfiguration
    BACKEND_URL: str = "http://localhost:8000"
    API_TIMEOUT: int = 10
    
    # Performance-Limits
    MAX_PREDICTION_LATENCY_MS: int = 2000
    MAX_MEMORY_USAGE_MB: int = 500
    
    # Demo-Konfiguration
    DEMO_DATA_LIMIT: int = 100
    
    # File-Pfade
    MODEL_PATH: str = "models/credit_risk_model.pkl"
    DATA_PATH: str = "data/credit_risk_dataset.csv"
    
    @classmethod
    def from_env(cls):
        """Lädt Konfiguration aus Umgebungsvariablen"""
        return cls(
            RANDOM_STATE=int(os.getenv('RANDOM_STATE', 42)),
            BACKEND_URL=os.getenv('BACKEND_URL', "http://localhost:8000"),
            DEMO_DATA_LIMIT=int(os.getenv('DEMO_DATA_LIMIT', 100))
        )
```

---

## 8. Professor Q&A - Prozess-Fokus

### Q1: Wie haben Sie die Datenaufbereitung strukturiert?
**A**: 4-stufiger Prozess: Datenladen/Validierung → Feature Engineering → Outlier Detection → Categorical Encoding. Jeder Schritt ist modular implementiert mit Error Handling. Siehe `frontend/utils/training.py:L50-200`.

### Q2: Welche Strategien haben Sie für unbalancierte Daten verwendet?
**A**: Stratified Train/Test Split, class_weight='balanced' im Random Forest, Imbalance Ratio Monitoring. Siehe `frontend/utils/training.py:L205-230`.

### Q3: Wie haben Sie die SHAP-Integration technisch umgesetzt?
**A**: TreeExplainer für Random Forest, Exception Handling für Robustheit, multiple Visualisierungsoptionen. Siehe `frontend/utils/prediction.py:L50-120`.

### Q4: Welche Performance-Optimierungen haben Sie implementiert?
**A**: Demo-Modus (100 statt vollständiger Kaggle-Dataset), Model-Caching, Async API-Calls, Memory-Monitoring. Siehe `frontend/utils/monitoring.py`.

### Q5: Wie haben Sie die Reproduzierbarkeit sichergestellt?
**A**: Konsistente Seeds (RANDOM_STATE=42), deterministische Algorithmen, Model-Persistence mit Metadaten. Siehe `frontend/utils/model_persistence.py`.

### Q6: Welche Code-Qualitätsmaßnahmen haben Sie implementiert?
**A**: Custom Exceptions, strukturiertes Logging, Configuration Management, Error Handling mit Graceful Degradation. Siehe `frontend/utils/error_handling.py`.

### Q7: Wie haben Sie die Frontend/Backend-Kommunikation implementiert?
**A**: REST API mit FastAPI, HTTP Status Codes, JSON Serialization, Timeout-Handling, Fallback-Mechanismus. Siehe `frontend/utils/api_client.py`.

### Q8: Welche Monitoring-Strategien haben Sie verwendet?
**A**: Performance-Monitoring (Latenz, Memory, Accuracy), Error-Rate Tracking, Uptime-Monitoring. Siehe `frontend/utils/monitoring.py`.

### Q9: Wie haben Sie die Modell-Persistierung implementiert?
**A**: Joblib für Model-Speicherung, JSON-Metadaten, Versionierung, Feature-Name-Persistierung. Siehe `frontend/utils/model_persistence.py`.

### Q10: Welche Sicherheitsmaßnahmen haben Sie implementiert?
**A**: Input Validation, SQL Injection Prevention, CORS-Konfiguration, Error Message Sanitization, Timeout-Limits.

---

**Version 2.2 erstellt**: $(date)
**Fokus**: Prozess-Struktur mit Code-Snippets
**Nächste Version**: v2.3 (Testing & Validation)
